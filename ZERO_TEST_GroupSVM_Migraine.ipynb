{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM for an Explainable Migraine Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "DATASET_PATH = \"./migraine.xls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Demografiche',\n",
       " 'Caratteristiche cliniche',\n",
       " 'Terapia',\n",
       " 'Sintomatologia',\n",
       " 'Caratteristiche molecolari',\n",
       " 'Biochimica clinica',\n",
       " 'Trigger']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(DATASET_PATH, skiprows=1)\n",
    "\n",
    "# columns name cleaner \n",
    "d_columns_temp = data.columns\n",
    "d_columns = []\n",
    "\n",
    "for c in d_columns_temp:\n",
    "    c_cleaned = c.split(\"\\n\")[0].lower()\n",
    "    d_columns.append(c_cleaned)\n",
    "\n",
    "data.columns = d_columns\n",
    "\n",
    "# features groups\n",
    "groups_temp = list(pd.read_excel(DATASET_PATH).columns.values)\n",
    "groups = []\n",
    "\n",
    "for index in range(len(groups_temp)):\n",
    "    if \"NA:\" not in groups_temp[index] and \"Unnamed:\" not in groups_temp[index]:\n",
    "        groups.append(groups_temp[index])\n",
    "        \n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cod.</th>\n",
       "      <th>età (all'arruolamento)</th>\n",
       "      <th>genere</th>\n",
       "      <th>menopausa</th>\n",
       "      <th>menarca (età)</th>\n",
       "      <th>emicrania</th>\n",
       "      <th>diagnosi</th>\n",
       "      <th>cefalea</th>\n",
       "      <th>lato</th>\n",
       "      <th>onset (età)</th>\n",
       "      <th>...</th>\n",
       "      <th>oc/hrt si=1/no=0</th>\n",
       "      <th>familiarità per patologie cerebrovascolari</th>\n",
       "      <th>familiarità per cardiopatia</th>\n",
       "      <th>ipertensione arteriosa</th>\n",
       "      <th>aritmie si=1/no=0</th>\n",
       "      <th>patologie cerebrovascolari</th>\n",
       "      <th>ima si=1/no=0</th>\n",
       "      <th>dislipidemia si=1/no=0</th>\n",
       "      <th>diabete si=1/no=0</th>\n",
       "      <th>risposta triptani ricodificata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BB12592</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>ESA</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOD001</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>3</td>\n",
       "      <td>EC</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOD002</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>3</td>\n",
       "      <td>EC+MOH</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOD003</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>EC+MOH</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOD004</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>EC</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cod.   età (all'arruolamento)  genere  menopausa  menarca (età)  \\\n",
       "0  BB12592                     42.0       1        0.0            NaN   \n",
       "1    SOD001                    42.0       1        0.0           15.5   \n",
       "2    SOD002                    38.0       1        0.0           12.5   \n",
       "3    SOD003                    44.0       0        NaN            NaN   \n",
       "4    SOD004                    72.0       0        NaN            NaN   \n",
       "\n",
       "  emicrania diagnosi cefalea  lato  onset (età)  ...  oc/hrt si=1/no=0  \\\n",
       "0         2      ESA       0   1.0         20.0  ...               0.0   \n",
       "1         3       EC       1   2.0         30.0  ...               NaN   \n",
       "2         3   EC+MOH       1   1.0         15.0  ...               0.0   \n",
       "3         3   EC+MOH       1   1.0         16.0  ...               NaN   \n",
       "4         3       EC       1   1.0         41.0  ...               NaN   \n",
       "\n",
       "   familiarità per patologie cerebrovascolari familiarità per cardiopatia  \\\n",
       "0                                         0.0                         0.0   \n",
       "1                                         NaN                         NaN   \n",
       "2                                         0.0                         0.0   \n",
       "3                                         1.0                         1.0   \n",
       "4                                         1.0                         0.0   \n",
       "\n",
       "   ipertensione arteriosa aritmie si=1/no=0  patologie cerebrovascolari  \\\n",
       "0                     0.0               0.0                         0.0   \n",
       "1                     NaN               NaN                         NaN   \n",
       "2                     0.0               0.0                         0.0   \n",
       "3                     0.0               0.0                         0.0   \n",
       "4                     0.0               0.0                         0.0   \n",
       "\n",
       "  ima si=1/no=0  dislipidemia si=1/no=0  diabete si=1/no=0  \\\n",
       "0           0.0                     0.0                0.0   \n",
       "1           NaN                     NaN                NaN   \n",
       "2           0.0                     0.0                0.0   \n",
       "3           0.0                     0.0                0.0   \n",
       "4           0.0                     0.0                0.0   \n",
       "\n",
       "  risposta triptani ricodificata  \n",
       "0                            0.0  \n",
       "1                            1.0  \n",
       "2                            1.0  \n",
       "3                            1.0  \n",
       "4                            1.0  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill NaN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def fill_binary_columns(list_of_indexes):\n",
    "    for index in list_of_indexes:\n",
    "        data[data.columns[index]] = data[data.columns[index]].fillna(-1)\n",
    "        \n",
    "def fill_categorical_columns(list_of_indexes):\n",
    "    for index in list_of_indexes:\n",
    "        filler = random.choice(list(data[data.columns[index]].unique()))\n",
    "        data[data.columns[index]] = data[data.columns[index]].fillna(filler)\n",
    "        \n",
    "def fill_range_columns(list_of_indexes):\n",
    "    for index in list_of_indexes:\n",
    "        data[data.columns[index]] = data[data.columns[index]].fillna(-1)\n",
    "\n",
    "def get_unique_range_value(index):\n",
    "    return list(data[data.columns[index]].unique())\n",
    "    \n",
    "def categorical_to_integer(row, c):\n",
    "    c = get_unique_range_value(c)\n",
    "    return  c.index(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN values\n",
    "columns = data.columns\n",
    "\n",
    "binary_columns = [2,3,7,8,10,14,15,16,13,17,22,23,24,25,73,74, 75, 77,78,79,80,81,82,83,84,85,86]\n",
    "categorical_columns = [20,21]\n",
    "categorical_columns.extend(list(range(26,71)))\n",
    "range_columns = [12]\n",
    "range_columns.extend(categorical_columns)\n",
    "\n",
    "fill_binary_columns(binary_columns)\n",
    "fill_categorical_columns(categorical_columns)\n",
    "fill_range_columns(range_columns)\n",
    "\n",
    "for c in range(len(columns)):\n",
    "    if c not in binary_columns and c not in categorical_columns and c not in range_columns and data[columns[c]].dtype != object:\n",
    "        data[columns[c]] = data[columns[c]].fillna(np.mean(data[columns[c]])) \n",
    "\n",
    "for c in range(len(range_columns)):\n",
    "    data[columns[c]] = data[columns[c]].apply(categorical_to_integer, args=(c,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values[500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_indexes = [range(1,4), range(5,15), range(16,20), range(22, 25), [27], range(46,71), range(72,77)]\n",
    "groups_dictionary = {}\n",
    "\n",
    "for gi in range(len(groups_indexes)):\n",
    "    groups_dictionary[groups[gi]] = list(groups_indexes[gi])\n",
    "    if 12 in groups_dictionary[groups[gi]]:\n",
    "        groups_dictionary[groups[gi]].remove(12)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, train, target_column, groups_dictionary):\n",
    "        self.data = train\n",
    "        self.target_column = target_column\n",
    "        self.groups = groups_dictionary\n",
    "        self.dataset = self.create_dataset()\n",
    "        self.dataset = shuffle(self.dataset)\n",
    "\n",
    "        \n",
    "    \n",
    "    def create_dataset(self):\n",
    "        codes = []\n",
    "        g1, g2, g3, g4, g5, g6, g7 = [], [], [], [], [], [], []\n",
    "        vectors = [g1, g2, g3, g4, g5, g6, g7]\n",
    "        targets = []\n",
    "        \n",
    "        for e in self.data.values:\n",
    "            codes.append(e[0])\n",
    "            for index in range(len(self.groups)):\n",
    "                vectors[index].append(np.array(e[self.groups[list(self.groups.keys())[index]]], dtype=object), )\n",
    "            targets.append(e[self.target_column])\n",
    "        \n",
    "        columns = [\"code\"]\n",
    "        columns.extend(groups)\n",
    "        columns.append(\"target\")\n",
    "        print(len(g5))\n",
    "        self.dataset_target = 8\n",
    "        return pd.DataFrame({columns[0]:codes, columns[1]:g1,columns[2]:g2,columns[3]:g3, columns[4]:g4,\n",
    "                             columns[5]:g5, columns[6]:g6, columns[7]:g7, columns[8]:targets})\n",
    "    \n",
    "    # function to split data in train and test, take in input the dataset, target_column name, \n",
    "    # test_size and random_state and return two tuple of training and test_set \n",
    "    def split_dataset(self, test_size=0.2, random_state = 42):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(self.dataset.drop([\"target\"], axis=1), self.dataset[\"target\"], \n",
    "                                                            test_size=test_size, random_state=random_state)\n",
    "        return (x_train, y_train), (x_test, y_test)\n",
    "    \n",
    "    def get_vectors(self, data):\n",
    "        v = []\n",
    "        for d in data.values:\n",
    "            v.append(d[1:])\n",
    "        return np.array(v)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 12\n",
    "\n",
    "dataset = Dataset(data, TARGET_COLUMN, groups_dictionary)\n",
    "train, test = dataset.split_dataset(test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Distribution\n",
    "\n",
    "Umbalanced dataset (**target 2**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(dataset.dataset[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the SVM model and the kernel function\n",
    "We can now define the svm model with sklearn library. We can also create a particular kernel function and pass it like argument to the svm\n",
    "\n",
    "```python\n",
    ">>> from sklearn import svm\n",
    ">>> def my_kernel(X, Y):\n",
    "...     return np.dot(X, Y.T)\n",
    "...\n",
    ">>> clf = svm.SVC(kernel=my_kernel)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel \n",
    "\n",
    "kernel function --> (a, b) --> (a * b) / sqrt(a^2 * b^2) --> result\n",
    "- a and b are group vector\n",
    "\n",
    "\n",
    "result --> ArrayMath.cosine(vector, weights) --> result\n",
    "- values are groups vector\n",
    "- weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def K(X,Y):\n",
    "    # function that compute single example function\n",
    "    v = []\n",
    "    for a,b in zip(X,Y):\n",
    "        # vector of computed values\n",
    "        v.append(compute_kernel(a, b))\n",
    "    # return vector with weight \n",
    "    return np.cos(np.dot(v, weights))\n",
    "\n",
    "\n",
    "def compute_kernel(X,Y):\n",
    "    # single component function\n",
    "    try:\n",
    "        norm_x = np.dot(X,X)\n",
    "        norm_y = np.dot(Y,Y)\n",
    "        if norm_x != 0  and norm_y != 0:\n",
    "            return np.divide(np.dot(X, Y), np.sqrt(np.dot(norm_x, norm_y)))\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def kernel_function(X, Y):\n",
    "        vector = []\n",
    "        gram_matrix = np.zeros((X.shape[0], Y.shape[0]))\n",
    "        for i, x in enumerate(X):\n",
    "            for j, y in enumerate(Y):\n",
    "                gram_matrix[i, j] = K(x, y)\n",
    "        return gram_matrix          \n",
    "\n",
    "\n",
    "class GroupKernel():\n",
    "    def __init__(self, weights):\n",
    "        self.weights = weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [1, 1, 1, 1, 1, 1, 1]\n",
    "group_kernel = GroupKernel(weights)\n",
    "\n",
    "x = dataset.get_vectors(train[0])\n",
    "y = train[1]\n",
    "gram_matrix = kernel_function(x, x)\n",
    "clf = svm.SVC(kernel = kernel_function) \n",
    "\n",
    "\n",
    "#print(kernel_function(train[0].values[0][1:], train[0].values[1][1:]))\n",
    "clf.fit(x, y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(dataset.get_vectors(test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_csv(data, preds, g_truth, file_id=0):\n",
    "    output = pd.DataFrame({\"cod\": data, \"preds\": preds, \"real_value\":g_truth})\n",
    "    output.to_csv(f\"./experiments/predictions-{file_id}.csv\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import time\n",
    "\n",
    "def random_search(max_iteration=20, iteration_id=0):\n",
    "    \n",
    "    best_iteration = 0\n",
    "    it = 0\n",
    "    best_f1 = -1\n",
    "    output = open(f\"./experiments/performances-{iteration_id}.txt\", \"w\")\n",
    "    \n",
    "    while(best_iteration < max_iteration - 1):\n",
    "        start_time = time.process_time()\n",
    "\n",
    "        # total iteration\n",
    "        print(f\"Iteration: {it+1}\") \n",
    "        print(f\"============================\")\n",
    "\n",
    "\n",
    "        # random weights initialization\n",
    "        global weights\n",
    "        \n",
    "        weights = np.zeros(7)\n",
    "        for w in range(len(weights)):\n",
    "            weights[w] = random.uniform(0,1)\n",
    "\n",
    "        group_kernel = GroupKernel(weights)\n",
    "\n",
    "        # values\n",
    "        x = dataset.get_vectors(train[0])\n",
    "        \n",
    "        # labels\n",
    "        y = train[1]\n",
    "\n",
    "        # svm with group kernel function\n",
    "        clf = svm.SVC(kernel = kernel_function) \n",
    "\n",
    "        # learning\n",
    "        clf.fit(x, y.values)\n",
    "        \n",
    "        # predictions\n",
    "        preds = clf.predict(dataset.get_vectors(test[0]))\n",
    "        \n",
    "        \n",
    "        # evaluation\n",
    "        precision = precision_score(preds, test[1].values, average=\"macro\")\n",
    "        recall = recall_score(preds, test[1].values, average=\"macro\") \n",
    "        f1 = f1_score(preds, test[1].values, average=\"macro\")\n",
    "        \n",
    "        \n",
    "        print(f\"Precision: {precision} Recall: {recall} F1: {f1}\\nWeights: {weights}\\n\")\n",
    "        # total time computation\n",
    "        total_time = time.process_time() - start_time\n",
    "        print(f\"Total time execution: {total_time}\")\n",
    "        # write execution time to file\n",
    "        time_file = open(f\"./experiments/time_of_execution-{iteration_id}.txt\", \"a\")\n",
    "        time_file.write(f\"{total_time}\\n\")\n",
    "        time_file.close  \n",
    "        \n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            print(\"Best F1\")            \n",
    "            best_iteration = 0\n",
    "            best_f1 = f1  \n",
    "            output.write(f\"Precision: {precision} Recall: {recall} F1: {f1}\\nWeights: {weights}\")\n",
    "            \n",
    "            create_prediction_csv(data=test[0][\"code\"], preds=preds, g_truth=test[1].values, file_id=iteration_id)\n",
    "\n",
    "        else:\n",
    "            best_iteration += 1\n",
    "            \n",
    "        it+=1\n",
    "        print(f\"Best Results: {best_iteration+1}/{20}\\n\\n\")\n",
    "        \n",
    "    output.close()\n",
    "\n",
    "    \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "for i in range(5):\n",
    "    random_search(max_iteration=20, iteration_id=f\"{str(datetime.datetime.now().date())}_{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
